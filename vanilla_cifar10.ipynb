{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from keras.datasets import cifar10\n",
    "from emnist import extract_training_samples\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "num_classes = 10 \n",
    "\n",
    "mean = np.mean(x_train,axis=(0, 1, 2, 3))\n",
    "std = np.std(x_train, axis=(0, 1, 2, 3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "# x_train = x_train/255.\n",
    "y_train = utils.to_categorical(y_train, num_classes) \n",
    "\n",
    "# x_test = x_test/255.\n",
    "y_test = utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(weight_decay= 0.00005, x_shape=[32,32,3], num_classes=10):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                         input_shape=x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                         input_shape=x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                         input_shape=x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                         input_shape=x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                         input_shape=x_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "   \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 552,874\n",
      "Trainable params: 551,722\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "196/196 [==============================] - 7s 29ms/step - loss: 1.8488 - accuracy: 0.3954 - val_loss: 1.8686 - val_accuracy: 0.3677\n",
      "Epoch 2/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 1.2727 - accuracy: 0.5584 - val_loss: 1.1015 - val_accuracy: 0.6254\n",
      "Epoch 3/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 1.0769 - accuracy: 0.6298 - val_loss: 0.9803 - val_accuracy: 0.6698\n",
      "Epoch 4/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.9683 - accuracy: 0.6712 - val_loss: 0.8710 - val_accuracy: 0.7076\n",
      "Epoch 5/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.8939 - accuracy: 0.6979 - val_loss: 0.7987 - val_accuracy: 0.7362\n",
      "Epoch 6/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.8363 - accuracy: 0.7198 - val_loss: 0.7600 - val_accuracy: 0.7487\n",
      "Epoch 7/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.7950 - accuracy: 0.7364 - val_loss: 0.7433 - val_accuracy: 0.7587\n",
      "Epoch 8/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.7514 - accuracy: 0.7538 - val_loss: 0.6848 - val_accuracy: 0.7794\n",
      "Epoch 9/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.7132 - accuracy: 0.7651 - val_loss: 0.6650 - val_accuracy: 0.7859\n",
      "Epoch 10/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.6860 - accuracy: 0.7792 - val_loss: 0.6647 - val_accuracy: 0.7915\n",
      "Epoch 11/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.6537 - accuracy: 0.7903 - val_loss: 0.6547 - val_accuracy: 0.7963\n",
      "Epoch 12/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.6342 - accuracy: 0.7995 - val_loss: 0.5945 - val_accuracy: 0.8143\n",
      "Epoch 13/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.6078 - accuracy: 0.8082 - val_loss: 0.5826 - val_accuracy: 0.8211\n",
      "Epoch 14/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5885 - accuracy: 0.8150 - val_loss: 0.5936 - val_accuracy: 0.8176\n",
      "Epoch 15/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5836 - accuracy: 0.8189 - val_loss: 0.5954 - val_accuracy: 0.8194\n",
      "Epoch 16/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5600 - accuracy: 0.8270 - val_loss: 0.5778 - val_accuracy: 0.8238\n",
      "Epoch 17/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5534 - accuracy: 0.8303 - val_loss: 0.5775 - val_accuracy: 0.8287\n",
      "Epoch 18/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5340 - accuracy: 0.8395 - val_loss: 0.5548 - val_accuracy: 0.8352\n",
      "Epoch 19/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5252 - accuracy: 0.8434 - val_loss: 0.5466 - val_accuracy: 0.8404\n",
      "Epoch 20/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5175 - accuracy: 0.8483 - val_loss: 0.5319 - val_accuracy: 0.8427\n",
      "Epoch 21/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5066 - accuracy: 0.8512 - val_loss: 0.5596 - val_accuracy: 0.8448\n",
      "Epoch 22/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.5019 - accuracy: 0.8533 - val_loss: 0.5437 - val_accuracy: 0.8421\n",
      "Epoch 23/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4869 - accuracy: 0.8581 - val_loss: 0.5586 - val_accuracy: 0.8420\n",
      "Epoch 24/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4814 - accuracy: 0.8608 - val_loss: 0.5172 - val_accuracy: 0.8540\n",
      "Epoch 25/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4849 - accuracy: 0.8611 - val_loss: 0.5660 - val_accuracy: 0.8421\n",
      "Epoch 26/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4720 - accuracy: 0.8673 - val_loss: 0.5346 - val_accuracy: 0.8552\n",
      "Epoch 27/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4648 - accuracy: 0.8700 - val_loss: 0.5537 - val_accuracy: 0.8489\n",
      "Epoch 28/250\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 0.4598 - accuracy: 0.8714 - val_loss: 0.5451 - val_accuracy: 0.8530\n",
      "Epoch 29/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4566 - accuracy: 0.8739 - val_loss: 0.5469 - val_accuracy: 0.8496\n",
      "Epoch 30/250\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 0.4571 - accuracy: 0.8741 - val_loss: 0.5376 - val_accuracy: 0.8589\n",
      "Epoch 31/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4480 - accuracy: 0.8775 - val_loss: 0.5574 - val_accuracy: 0.8551\n",
      "Epoch 32/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4416 - accuracy: 0.8811 - val_loss: 0.5601 - val_accuracy: 0.8512\n",
      "Epoch 33/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4416 - accuracy: 0.8826 - val_loss: 0.5810 - val_accuracy: 0.8461\n",
      "Epoch 34/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4382 - accuracy: 0.8837 - val_loss: 0.5455 - val_accuracy: 0.8587\n",
      "Epoch 35/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4361 - accuracy: 0.8832 - val_loss: 0.5417 - val_accuracy: 0.8626\n",
      "Epoch 36/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4324 - accuracy: 0.8869 - val_loss: 0.5403 - val_accuracy: 0.8629\n",
      "Epoch 37/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4253 - accuracy: 0.8907 - val_loss: 0.5435 - val_accuracy: 0.8606\n",
      "Epoch 38/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4306 - accuracy: 0.8889 - val_loss: 0.5423 - val_accuracy: 0.8611\n",
      "Epoch 39/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4287 - accuracy: 0.8902 - val_loss: 0.5389 - val_accuracy: 0.8619\n",
      "Epoch 40/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4256 - accuracy: 0.8905 - val_loss: 0.5503 - val_accuracy: 0.8581\n",
      "Epoch 41/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4206 - accuracy: 0.8918 - val_loss: 0.6135 - val_accuracy: 0.8491\n",
      "Epoch 42/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4175 - accuracy: 0.8954 - val_loss: 0.5553 - val_accuracy: 0.8629\n",
      "Epoch 43/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4175 - accuracy: 0.8965 - val_loss: 0.5621 - val_accuracy: 0.8574\n",
      "Epoch 44/250\n",
      "196/196 [==============================] - 5s 26ms/step - loss: 0.4135 - accuracy: 0.8976 - val_loss: 0.5466 - val_accuracy: 0.8649\n",
      "Epoch 45/250\n",
      "196/196 [==============================] - 5s 25ms/step - loss: 0.4147 - accuracy: 0.8966 - val_loss: 0.5656 - val_accuracy: 0.8606\n",
      "Epoch 46/250\n",
      " 57/196 [=======>......................] - ETA: 3s - loss: 0.4003 - accuracy: 0.9019"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-08c16771802b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/iet_env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iet_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iet_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iet_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iet_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/iet_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iet_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256, epochs=250, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iet_env",
   "language": "python",
   "name": "iet_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
