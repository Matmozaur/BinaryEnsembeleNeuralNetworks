{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from emnist import extract_training_samples\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "import tempfile\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import json\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../../..'))\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "tf.config.list_physical_devices('GPU')\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(m):\n",
    "    _, keras_file = tempfile.mkstemp('.h5')\n",
    "    m.save(keras_file, include_optimizer=True)\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(keras_file)\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "show_dataset(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10 \n",
    "\n",
    "mean = np.mean(x_train,axis=(0, 1, 2))\n",
    "std = np.std(x_train, axis=(0, 1, 2))\n",
    "\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "y_train = utils.to_categorical(y_train, num_classes) \n",
    "y_test = utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"vanilla_fashion_mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(full_evaluate(model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['base'] = full_evaluate(model, x_test, y_test)\n",
    "results['base']['size (kb)'] = os.stat('vanilla_fashion_mnist.h5').st_size//1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sparse(model_for_pruning, epochs):\n",
    "    model_for_pruning.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    logdir = tempfile.mkdtemp()\n",
    "\n",
    "    callbacks = [\n",
    "      tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "      tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    ]\n",
    "\n",
    "    model_for_pruning.fit(x_train, y_train,\n",
    "                      batch_size=batch_size, epochs=epochs,\n",
    "                      callbacks=callbacks,\n",
    "                        validation_data=(x_test, y_test)\n",
    "                         )\n",
    "\n",
    "\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    return model_for_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in [0.5, 0.7, 0.8, 0.85, 0.9, 0.925, 0.95, 0.975, 0.99]:\n",
    "#     pruning_params = {\n",
    "#           'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.2,\n",
    "#                             final_sparsity=p,\n",
    "#                             begin_step=0,\n",
    "#                             end_step=np.ceil(x_train.shape[0] / batch_size).astype(np.int32) * epochs)\n",
    "#     }\n",
    "\n",
    "#     model_for_pruning = prune_low_magnitude(tf.keras.models.clone_model(model), **pruning_params)\n",
    "#     model_for_export = train_sparse(model_for_pruning, int(epochs*p))\n",
    "#     results['weight_pruning_{}'.format(p)] = full_evaluate(model_for_export, x_test, y_test)\n",
    "#     results['weight_pruning_{}'.format(p)]['size (kb)'] = get_gzipped_model_size(model_for_export)//1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('results_pruning.json', 'w', encoding ='utf8') as json_file:\n",
    "#     json.dump(results, json_file, ensure_ascii = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tmp = tf.keras.models.clone_model(model)\n",
    "# acc = []\n",
    "# par_count =[]\n",
    "models = [model_tmp]\n",
    "model_tmp.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "model_tmp = prune_model(model_tmp, 0.3, opt='adam', method='l1')\n",
    "\n",
    "for i in range(100):\n",
    "    try:\n",
    "        model_tmp = prune_model(model_tmp, 0.1, opt='adam', method='l1')\n",
    "    except:\n",
    "        break\n",
    "    model_tmp.fit(x_train, y_train, batch_size=256, epochs=15, validation_data=(x_test, y_test), verbose=1)\n",
    "    results['node_pruning_{}'.format((0.9)**(i+4))] = full_evaluate(model_tmp, x_test, y_test)\n",
    "    results['node_pruning_{}'.format((0.9)**(i+4))]['params'] = model_tmp.count_params()\n",
    "    results['node_pruning_{}'.format((0.9)**(i+4))]['size (kb)'] = get_gzipped_model_size(model_tmp)//1024\n",
    "    with open('results_pruning.json', 'w', encoding ='utf8') as json_file:\n",
    "        json.dump(results, json_file, ensure_ascii = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_pruning.json', 'r', encoding ='utf8') as json_file:\n",
    "    results = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     results['node_pruning_{}'.format((0.9)**(i+1))] = results['node_pruning_{}'.format((0.1)**(i+1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     del results['node_pruning_{}'.format((0.1)**(i+1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('results_pruning.json', 'w', encoding ='utf8') as json_file:\n",
    "#         json.dump(results, json_file, ensure_ascii = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iet_env_um",
   "language": "python",
   "name": "iet_env_um"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
